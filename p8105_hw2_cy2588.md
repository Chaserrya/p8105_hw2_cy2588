p8105\_hw2\_cy2588
================
Chufeng Yang
09/25/2020

``` r
library(tidyverse)
```

    ## ─ Attaching packages ───────────────────────────────────────────── tidyverse 1.3.0 ─

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ─ Conflicts ─────────────────────────────────────────────── tidyverse_conflicts() ─
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## problem 1

path to data:

``` r
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read and clean the Mr. Trash Wheel sheet:

``` r
trashwheel_df = 
    read_xlsx(
        path = path_to_data,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
    )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2018 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2018) %>% 
    relocate(year)
precip_2017 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2017 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2017) %>% 
    relocate(year)
```

combine precipitation datasets and convert month to a character
variable.

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )
precip_df = 
    bind_rows(precip_2018, precip_2017)
precip_df =
    left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The
Mr. Trash Wheel spreadsheet is largely self-explanatory, and includes
information on the dumpter number, date of collection, amount of total
litter and litter type. The dataset contains information on year, month,
and trash collected, include some specific kinds of trash. There are a
total of 344 rows in our final dataset. Additional data sheets include
month precipitation data.

In this precipitation dataset: \* The total precipitation in 2018 was
70.33 inches. \* The median number of sports balls found in a dumpster
in 2017 was 8

## problem 2

read and clear data

``` r
nyc_transit_df= 
    read.csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names()  %>% 
  select(line: entry, vending, ada) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE))%>% 
  mutate(vending = recode(vending, YES = TRUE, NO = FALSE))
```

This dataset contains . As trash enters the inner harbor, the trashwheel
collects that trash, and stores it in a dumpster. The Mr. Trash Wheel
spreadsheet is largely self-explanatory, and includes information on the
dumpter number, date of collection, amount of total litter and litter
type. The dataset contains information on , include . There are a total
of 1868 rows and 19 cols in the resulting dataset.

How many distinct stations are there?

``` r
distinct_stations = nyc_transit_df  %>% 
    distinct(station_name, line, .keep_all = T)
```

There are 465 distinct stations.

How many stations are ADA compliant?

``` r
ADA_comliant = filter(distinct_stations, ada == T)
```

There are 84 stations are ADA compliant.

What proportion of station entrances / exits without vending allow
entrance?

``` r
without_vending = filter(nyc_transit_df, vending == F)
allow = filter(without_vending, entry == T)
proportion_allow = nrow(allow)/ nrow(without_vending)
```

The proportion of station entrances / exits without vending allow
entrance is 37.704918%

Now, reformat the data

``` r
reformate_data = distinct_stations%>% 
  mutate_at(vars(route8:route11), as.character)%>%
pivot_longer(
   route1:route11,
   names_to = "route_name",
   values_to = "route_number" )
tail(reformate_data)
```

    ## # A tibble: 6 x 10
    ##   line  station_name station_latitude station_longitu… entrance_type entry
    ##   <chr> <chr>                   <dbl>            <dbl> <chr>         <lgl>
    ## 1 Flus… 34 St Hudso…             40.8            -74.0 Elevator      TRUE 
    ## 2 Flus… 34 St Hudso…             40.8            -74.0 Elevator      TRUE 
    ## 3 Flus… 34 St Hudso…             40.8            -74.0 Elevator      TRUE 
    ## 4 Flus… 34 St Hudso…             40.8            -74.0 Elevator      TRUE 
    ## 5 Flus… 34 St Hudso…             40.8            -74.0 Elevator      TRUE 
    ## 6 Flus… 34 St Hudso…             40.8            -74.0 Elevator      TRUE 
    ## # … with 4 more variables: vending <lgl>, ada <lgl>, route_name <chr>,
    ## #   route_number <chr>

``` r
distinct_station_A = filter(reformate_data, route_number == "A")
ADA_comliant_A = filter(distinct_station_A, ada == T)
```

There are 60 distinct stations serve the A train. 17 of the stations are
ADA compliant.

## problem 3

First, clean the data in pols-month.csv

``` r
month_df_p3 = 
    tibble(
        month = 1:12,
        month_name = month.name
    )
pols_month_df= 
    read.csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
    janitor::clean_names()  %>% 
  separate(mon, into = c("year","month","day")) %>%
  mutate_at(vars(year:day), as.numeric) 
tidy_data_mon = left_join(pols_month_df, month_df_p3, by = "month") %>%
  mutate(month = month_name) %>%
  select(-month_name) %>%
mutate(president = case_when(
    prez_gop == "1" ~ "gop",
    prez_dem == "1" ~ "dem"
  )) %>% 
  select(-day, -prez_gop, -prez_dem)
  tail(tidy_data_mon)
```

    ##     year    month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ## 817 2015  January      31      54     245      18      44     188       dem
    ## 818 2015 February      31      54     245      18      44     188       dem
    ## 819 2015    March      31      54     245      18      44     188       dem
    ## 820 2015    April      31      54     244      18      44     188       dem
    ## 821 2015      May      31      54     245      18      44     188       dem
    ## 822 2015     June      31      54     246      18      44     188       dem

Second, clean the data in snp.csv using a similar process to the above

``` r
snp_df= 
    read.csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
    janitor::clean_names() %>% 
  separate(date, into = c("month","day","year")) %>% 
  relocate(year,month)
  str(snp_df)
```

    ## 'data.frame':    787 obs. of  4 variables:
    ##  $ year : chr  "2015" "2015" "2015" "2015" ...
    ##  $ month: chr  "7" "6" "5" "4" ...
    ##  $ day  : chr  "1" "1" "1" "1" ...
    ##  $ close: num  2080 2063 2107 2086 2068 ...

Third, tidy the unemployment data so that it can be merged with the
previous datasets.

``` r
unemployment_df= 
    read.csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
    janitor::clean_names() %>% 
  pivot_longer(
   jan:dec,
   names_to = "month",
   values_to = "percentage" )
 str(unemployment_df)
```

    ## tibble [816 × 3] (S3: tbl_df/tbl/data.frame)
    ##  $ year      : int [1:816] 1948 1948 1948 1948 1948 1948 1948 1948 1948 1948 ...
    ##  $ month     : chr [1:816] "jan" "feb" "mar" "apr" ...
    ##  $ percentage: num [1:816] 3.4 3.8 4 3.9 3.5 3.6 3.6 3.9 3.8 3.7 ...

Join the datasets
