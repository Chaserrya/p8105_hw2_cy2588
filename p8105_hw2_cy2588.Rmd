---
title: "p8105_hw2_cy2588"
output: github_document
author: Chufeng Yang
date: 09/25/2020
---

```{r setup}
library(tidyverse)
library(readxl)
```

## problem 1

path to data:  

```{r}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read and clean the Mr. Trash Wheel sheet:  

```{r}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
	)
```

Read precipitation data for 2018 and 2017.   

```{r}
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2018) %>% 
	relocate(year)
precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2017) %>% 
	relocate(year)
```

combine precipitation datasets and convert month to a character variable.  

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)
precip_df = 
	bind_rows(precip_2018, precip_2017)
precip_df =
	left_join(precip_df, month_df, by = "month")
```


This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The Mr. Trash Wheel spreadsheet is largely self-explanatory, and includes information on the dumpter number, date of collection, amount of total litter and litter type.  

The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. 

In this precipitation dataset:  

* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.  
* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`

## problem 2

read and clear data

```{r}
nyc_transit_df= 
	read.csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
	janitor::clean_names()  %>% 
  select(line: entry, vending, ada) %>% 
  mutate(
    entry = recode(entry, YES = TRUE, NO = FALSE),
    vending = recode(vending, YES = TRUE, NO = FALSE)
    )
```
Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

* The dataset contains information related to each entrance and exit for each subway station in NYC, including such as stations' name, latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.  
* So far, I have just cleaned their names and selected columns of interest and changed some date type.  
* There are a total of `r nrow(nyc_transit_df)` rows and `r ncol(nyc_transit_df)` cols in the resulting dataset，, which is not tidy at all.  

How many distinct stations are there? 

```{r}
distinct_stations = nyc_transit_df  %>% 
	distinct(station_name, line, .keep_all = T)
```
* There are `r nrow(distinct_stations)` distinct stations.

How many stations are ADA compliant?

```{r}
ADA_compliant = filter(distinct_stations, ada == T)
```
* There are `r nrow(ADA_compliant)` stations are ADA compliant.

What proportion of station entrances / exits without vending allow entrance?
```{r}
without_vending = filter(nyc_transit_df, vending == F)
allow_entr = filter(without_vending, entry == T)
```
* The proportion of station entrances / exits without vending allow entrance is `r nrow(allow_entr)/ nrow(without_vending)*100`%  

Now, reformat the data

```{r}
reformate_data = distinct_stations%>% 
  mutate_at(vars(route8:route11), as.character)%>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    values_to = "route_number" )
distinct_station_A = filter(reformate_data, route_number == "A")
ADA_comliant_A = filter(distinct_station_A, ada == T)
```
* There are `r nrow(distinct_station_A)` distinct stations serve the A train.  
* `r nrow(ADA_comliant_A)` of the stations are ADA compliant.

## problem 3

First, clean the data in pols-month.csv.

```{r}
pols_month_df= 
	read.csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
	janitor::clean_names()  %>% 
  separate(mon, into = c("year","month","day")) %>%
  mutate_at(vars(year:day), as.numeric) %>%
  left_join(month_df, by = "month") %>%
  mutate(month = month_name) %>%
  select(-month_name) %>%
  mutate(
    president = case_when(
      prez_gop == "1" ~ "gop",
      prez_dem == "1" ~ "dem"
  )) %>% 
  select(-day, -prez_gop, -prez_dem)
```


Second, clean the data in snp.csv using a similar process to the above.

```{r}
snp_df= 
	read.csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
	janitor::clean_names() %>% 
  separate(date, into = c("day","month","year")) %>%
  mutate_at(vars(year:day), as.numeric) %>%
  left_join(month_df, by = "month") %>%
  mutate(month = month_name) %>%
  select(-month_name, -day) %>%
  relocate(year,month)
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. 

```{r}
unemployment_df= 
	read.csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
	janitor::clean_names() 
colnames(unemployment_df)[2:13] = month.name
unemployment_df = pivot_longer(unemployment_df,
   January:December,
   names_to = "month",
   values_to = "unempolyment_%" )
```

Join the datasets

```{r}
result_df = pols_month_df %>%
  left_join(snp_df, by = c("month","year")) %>%
  left_join(unemployment_df, by = c("month","year"))
```

Explain briefly what each dataset contained, and describe the resulting dataset.  

* The first dataset “pols-month” contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time.  
* The second dataset “snp” contains 787 observations of 2 variables related to Standard & Poor’s stock market index (S&P), often used as a representative measure of stock market as a whole.  
* The third dataset  “unemployment” contains 68 observations of 13 variables related to the umemployment rate at any given time.  
* The resulting dataset is in `r nrow(result_df)` x `r ncol(result_df)` dimension, and the years range of data is `r range(pull(result_df, year))`. The resulting dataset contains 11 variables, which are: `r names(result_df)`.  



